\section{Matériels et Méthodes}
\subsection{Le cluster de calcul et Slurm}
Le Genoscope possède un cluster (\emph{inti}) de calcul de 71 noeuds répartis sur 5 partitions. La partition \og normal\fg{} est composée de 47 noeuds qui disposent entre 12 et 36 coeurs et entre 96 et 386 Go de Ram. La partition \og small\fg{} est composée de 8 noeuds dont 4 qui possèdent 8 coeurs et 64 Go de Ram, et 4 autres qui disposent de 16 coeurs et 128 Go de Ram. Cette partition est utilisée pour les processus courts et/ou qui demande peu de mémoire Ram. Les partitions \og xlarge \fg{} et \og xxlarge\fg{} ont chacun deux noeuds composés de 48 coeurs et 2To de Ram, de 56 coeurs et 6To de Ram respectivement. Ces deux partitions sont utilisées pour les processus demandant plusieurs jours ou semaines de calculs.
La partition \og production\fg{} du cluster \emph{inti} est composée de 12 noeuds qui disposent de 16 coeurs et de 257 Go de Ram. Les différents pipeline du workflow NGS utilisent cette partition.
L'accès à l'utilisation du cluster et de ses noeuds est réalisé par le logiciel \href{https://slurm.schedmd.com/documentation.html}{Slurm}.

\subsection{La base de données de référence NGL et la gestion des projets}
Le Genoscope dispose de sa propre base de données de référence (NGL). Celle-ci est divisée en plusieurs parties. NGL\_BI, est la partie de la base de données utilisée par les équipes de bioinformatique. NGL\_SEQ, est la partie de la base de données utilisée dès la réception des échantillons et jusqu'au séquençage de ces derniers. Il y a également les parties NGL\_SUB, NGL\_REAGENT et NGL\_PROJECTS. La gestion et le suivi des développements informatiques sont réalisés par le système de tickets \href{https://www.atlassian.com/fr/software/jira}{Jira}.

\subsection{Le langage de programmation Perl}
L'écriture du workflow des pipelines pour les séquenceurs MGI sera réalisée dans le langage de programmation Perl. L'utilisation de ce langage est rendu nécessaire pour des raisons historiques du laboratoire, puisque de nombreuses librairies et modules qui seront utilisés dans le développement des pipelines sont écrits en Perl.\\

C'est pour toutes ces raisons qu'il m'a été nécessaire d'apprendre à coder en Perl. j'ai donc commencé par réaliser un programme permettant de faire des analyses statistiques élémentaires sur des fichiers FASTQ, tel que le taux de GC, la moyenne du score de la qualité, ainsi que plusieurs autres métriques. Le programme est capable de gérer les fichiers FASTQ issue de séquençage \emph{single end\footnote{Lecture dans un seul sens des reads par le séquenceur}} et \emph{paired end\footnote{Lecture dans les deux sens des reads par le séquenceur}}. Cela m'a permis de prendre en main les librairies Perl utilisées pour les différents pipelines déjà en place. Ainsi que de m'habituer à l'environnement de travail, l'utilisation du lancement de job sur les noeuds de calculs et l'utilisation des modules\footnote{Un module contient un ou plusieurs logiciels tiers ou développé par les équipes du Genoscope. Il est néccessaire de les charger dans notre environement de travail pour pouvoir utiliser ces ces derniers.} pour les différents pipelines.

\subsection{Librairie et API Perl permettant d'interagir avec la base de données NGL}
L'interaction entre les pipelines du workflow NGS et la base de données NGL s'effectue par des fichiers JSON\footnote{\emph{JavaScript Object Notation} est un format de données textuelles structurées et organisées}.
Cette interaction est possible grâce à une API\footnote{\emph{application programming interface} est une interface logicielle qui permet de \og connecter \fg{} un logiciel ou un service à un autre logiciel ou service afin d'échanger des données et des fonctionnalités} développé en Perl par l'équipe de \og production\fg{} du LBGB, elle permet d'ajouter, modifier, récupérer, supprimer des données des fichiers JSON. Une librairie Perl (\emph{DBFactory}) permet d'interagir avec cette API directement depuis une autre librairie ou script Perl, c'est cette dernière qui sera utilisé dans le développement des pipelines du workflow NGS pour la technologie MGI.

\subsection{Logiciels de démultipléxage et génération de fichiers de séquences (bcl2fastq - bcl-convert)}
\label{DBFactory}
Ces deux logiciels de génération de fichiers de séquences et de démultipléxage (bcl2fastq et bcl-convert), sont tous deux développés et commercialisés par Illumina. Cette évaluation entre ces deux logiciels est nécessaire pour déterminer les changements qu'il y aura à faire dans les pipelines de génération de fichiers de séquences pour la technologie Illumina, en vue du remplacement de bcl2fastq (qui sera bientôt obsolète) par bcl-convert.

Dans un premier temps, il est nécessaire de déterminer les conditions optimales de bcl2fastq (temps total (\emph{Elapsed time}\footnote{Temps écoulé entre le début du programme et le fin de celui-ci}), temps CPU (\emph{CPU time}\footnote{Temps d'utilisation des cpu par le programme}), pourcentage d'utilisation CPU (\emph{\%CPU}\footnote{((\emph{CPU time} + temps utilisé par les appels système ) / \emph{Elapsed time} ) / nombres de CPU utilisé par le programme})) en fonction des ressources disponibles sur les noeuds du cluster (\emph{inti}) réservé à la \emph{prodution}, afin de pouvoir comparer les performances des 2 logiciels. Les conditions optimales sont déterminées en fonction des paramètres suivants de bcl2fastq (l'équivalent de bcl-convert est indiqué entre crochets): \\
\begin{itemize}
    \item[•] \texttt{r} [bcl-num-decompression-threads] : nombre de \emph{threads}\footnote{Processus : instructions du langage machine d'un processeur.} accordé pour la décompression et la lecture des \emph{Bases Calls}\footnote{Fichier d'attribution des bases nucléiques en fonction des pics du chromatogramme lors du séquençage}
    \item[•] \texttt{p} [bcl-num-conversion-threads] : nombre de \emph{threads} accordé pour la conversion des \emph{Bases Calls} en fastq
    \item[•] \texttt{w} [bcl-num-compression-threads] : nombre de \emph{threads} accordé l'écriture et la compression des fichiers fastq\\
\end{itemize}

J'ai réalisés tous ces tests sur le même noeud de calcul, dans l'objectif de minimiser les biais. La comparaison est effectuée sur le temps total du démultipléxage, ainsi que sur le temps CPU et le pourcentage d'utilisation des CPU.

\subsection{Les pipelines de génération de fichiers de séquences pour les technologies Illumina et Nanopore}
Les pipelines de générations de fichiers de séquences pour les technologies Illumina et Nanopore réalisent dans un premier temps le démultipléxage permettant la création des fichiers de séquences correspondant aux échantillons et des fichiers de statistiques de ces derniers. Ils créent les runs, les pistes, et les readset dans NGL\_BI en y insérant les métriques, graphiques et fichiers permettant leurs évaluations.\\

Concernant le pipeline de génération de fichiers de séquences pour la technologie MGI, j'ai de développé un pipeline dont l'objectif final est le même que celui d'Illumina en prenant en compte que le démultipléxage est directement réalisé par les séquenceurs. Les métriques, graphiques et fichiers de statistiques sont également différents d'Illumina. Il sera donc nécessaire de trouver comment obtenir les métriques, graphiques et fichiers, ou de les calculer, à partir des données générées par le séquenceur, pour permettre de les insérer dans NGL\_BI

\subsection{Les pipelines de contrôle qualité des lots de séquences pour les technologies Illumina et Nanopore}
Les pipelines de contrôle qualité des lots de séquences réalisent différentes étapes de contrôle qualité et de nettoyage des lots de séquences. Ils réalisent le contrôle qualité et l'estimation des duplicats de séquence des fichiers avant et après nettoyage (\emph{trimming}), ils retirent le \emph{PhiX}\footnote{Parties du génome du phage \emph{Lambda} qui sont ajoutés sur les pistes des flowcell avant le séquençage, permettant de contrôler le bon déroulé du séquençage.} (pour les technologies Illumina), réalisent l'assignation taxonomique des séquences, réalisent un alignement des séquences si un génome de référence existe, réalisent le calcul du pourcentage de séquences qui ont leurs reads \emph{forward} (brin sens) et \emph{reverse} (brin anti-sens) qui se chevauchent et réalisent la distribution des fichiers de séquences nettoyés dans leurs répertoires de projet, d'échantillon, de type de technologie et de run.\\

Concernant le pipeline de contrôle qualité des fichiers de séquences pour la technologie MGI, il s'agira de développer un pipeline dont l'objectif est le même que celui d'Illumina en prenant en compte qu'avec cette technologie il n'y auras pas de \emph{PhiX} à enlever dans les fichiers de séquences.
